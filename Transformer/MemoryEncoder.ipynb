{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskDownSampler(nn.Module):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        nn (_type_): _description_\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dim: int=256,  # 最后的编码维度，也是输出通道数\n",
    "        kernel_size: int=4,\n",
    "        stride: int=4,\n",
    "        padding: int=0,\n",
    "        total_stride: int=16,\n",
    "        activation: nn.Module=nn.ReLU,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        num_layers = int(math.log2(total_stride) // math.log2(stride))\n",
    "        assert stride ** num_layers == total_stride\n",
    "        self.encoder = nn.Sequential()\n",
    "        mask_in_chans, mask_out_chans = 1, 1\n",
    "        for _ in range(num_layers):\n",
    "            mask_out_chans = mask_in_chans * (stride**2)\n",
    "            self.encoder.append(\n",
    "                nn.Conv2d(\n",
    "                    mask_in_chans,\n",
    "                    mask_out_chans,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=stride,\n",
    "                    padding=padding,\n",
    "                )\n",
    "            )\n",
    "            self.encoder.append(LayerNorm2d(mask_out_chans))\n",
    "            self.encoder.append(activation())\n",
    "            mask_in_chans = mask_out_chans\n",
    "\n",
    "        self.encoder.append(nn.Conv2d(mask_out_chans, embedding_dim, kernel_size=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CXBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        kernel_size: int=7,\n",
    "        padding: int=3,\n",
    "        drop_path: int=0.0,\n",
    "        layer_scale_init_value=1e-6,\n",
    "        use_dwconv=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dwconv = nn.Conv2d(\n",
    "            dim,\n",
    "            dim,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=padding,\n",
    "            groups=dim if use_dwconv else 1,\n",
    "        )\n",
    "        self.norm = LayerNorm2d(dim, eps=1e-6)\n",
    "        self.pwconv1 = nn.Linear(\n",
    "            dim, 4 * dim\n",
    "        )\n",
    "        self.act = nn.GELU()\n",
    "        self.pwconv2 = nn.Linear(\n",
    "            4 * dim, dim\n",
    "        )\n",
    "        self.gamma = (\n",
    "            nn.Parameter(layer_scale_init_value * torch.ones((dim)), requires_grad=True)\n",
    "            if layer_scale_init_value > 0\n",
    "            else None\n",
    "        )  # 可学习参数\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0.0 else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        input = x\n",
    "        x = self.dwconv(x)\n",
    "        x = self.norm(x)\n",
    "        x = x.permute(0, 2, 3, 1)  # (N, C, H, W) -> (N, H, W, C)\n",
    "        x = self.pwconv1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pwconv2(x)\n",
    "        if self.gamma is not None:\n",
    "            x = self.gamma * x\n",
    "        x = x.permute(0, 3, 1, 2)  # (N, H, W, C) -> (N, C, H, W)\n",
    "\n",
    "        x = input + self.drop_path(x)\n",
    "        return x\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
