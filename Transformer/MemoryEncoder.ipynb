{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskDownSampler(nn.Module):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        nn (_type_): _description_\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dim: int=256,  # 最后的编码维度，也是输出通道数\n",
    "        kernel_size: int=4,\n",
    "        stride: int=4,\n",
    "        padding: int=0,\n",
    "        total_stride: int=16,\n",
    "        activation: nn.Module=nn.ReLU,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        num_layers = int(math.log2(total_stride) // math.log2(stride))\n",
    "        assert stride ** num_layers == total_stride\n",
    "        self.encoder = nn.Sequential()\n",
    "        mask_in_chans, mask_out_chans = 1, 1\n",
    "        for _ in range(num_layers):\n",
    "            mask_out_chans = mask_in_chans * (stride**2)\n",
    "            self.encoder.append(\n",
    "                nn.Conv2d(\n",
    "                    mask_in_chans,\n",
    "                    mask_out_chans,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=stride,\n",
    "                    padding=padding,\n",
    "                )\n",
    "            )\n",
    "            self.encoder.append(LayerNorm2d(mask_out_chans))\n",
    "            self.encoder.append(activation())\n",
    "            mask_in_chans = mask_out_chans\n",
    "\n",
    "        self.encoder.append(nn.Conv2d(mask_out_chans, embedding_dim, kernel_size=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CXBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        kernel_size: int=7,\n",
    "        padding: int=3,\n",
    "        drop_path: int=0.0,\n",
    "        layer_scale_init_value=1e-6,\n",
    "        use_dwconv=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dwconv = nn.Conv2d(\n",
    "            dim,\n",
    "            dim,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=padding,\n",
    "            groups=dim if use_dwconv else 1,\n",
    "        )\n",
    "        self.norm = LayerNorm2d(dim, eps=1e-6)\n",
    "        self.pwconv1 = nn.Linear(\n",
    "            dim, 4 * dim\n",
    "        )\n",
    "        self.act = nn.GELU()\n",
    "        self.pwconv2 = nn.Linear(\n",
    "            4 * dim, dim\n",
    "        )\n",
    "        self.gamma = (\n",
    "            nn.Parameter(layer_scale_init_value * torch.ones((dim)), requires_grad=True)\n",
    "            if layer_scale_init_value > 0\n",
    "            else None\n",
    "        )  # 可学习参数\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0.0 else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        input = x\n",
    "        x = self.dwconv(x)\n",
    "        x = self.norm(x)\n",
    "        x = x.permute(0, 2, 3, 1)  # (N, C, H, W) -> (N, H, W, C)\n",
    "        x = self.pwconv1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pwconv2(x)\n",
    "        if self.gamma is not None:\n",
    "            x = self.gamma * x\n",
    "        x = x.permute(0, 3, 1, 2)  # (N, H, W, C) -> (N, C, H, W)\n",
    "\n",
    "        x = input + self.drop_path(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fuser(nn.Module):\n",
    "    def __init__(self, layer, num_layers, dim=None, input_projection=False):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Identity()\n",
    "        self.layers = get_clones(layer, num_layers)\n",
    "\n",
    "        if input_projection:\n",
    "            assert dim is not None\n",
    "            self.proj = nn.Conv2d(dim, dim, kernel_size=1)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.proj(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        out_dim,\n",
    "        mask_downsampler,\n",
    "        fuser,\n",
    "        position_encoding,\n",
    "        in_dim = 256,\n",
    "    ):\n",
    "        self.mask_downsampler = mask_downsampler\n",
    "        self.pix_feat_proj = nn.Conv2d(in_dim, in_dim, kernel_size=1)\n",
    "        self.fuser = fuser\n",
    "        self.position_encoding = position_encoding\n",
    "        self.out_proj = nn.Identity()\n",
    "        if out_dim != in_dim:\n",
    "            self.out_proj = nn.Conv2d(in_dim, out_dim, kernel_size=1)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        pix_feat: torch.Tensor,\n",
    "        masks: torch.Tensor,\n",
    "        skip_mask_sigmoid: bool = False,\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # 处理mask\n",
    "        if not skip_mask_sigmoid:\n",
    "            masks = F.sigmoid(masks)\n",
    "        masks = self.mask_downsampler(masks)\n",
    "\n",
    "        # 处理pix_fear\n",
    "        pix_feat = pix_feat.to(masks.device)\n",
    "        x = self.pix_feat_proj(pix_feat)\n",
    "\n",
    "        # 融合\n",
    "        x = x + masks\n",
    "        x = self.fuser(x)\n",
    "        x = self.out_proj(x)\n",
    "\n",
    "        pos = self.position_encoding(x).to(x.dtype)\n",
    "\n",
    "        return {\"vision_features\": x, \"vision_pos_enc\": [pos]}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
